---
title: "Quantifying relationships between environmental factors and accumulated tornado power on the most prolific days in the largest ``outbreaks"
author: "Zoe Schroder/James Elsner"
date: "7/31/2018"
output: github_notebook
editor_options:
  chunk_output_type: console
---

Research to be submitted to the **Electronic Journal of Severe Storms Meteorology**

## Part 1: Tornado data

Set working directory and load packages. Suppress the messages of the packages. 
```{r}
suppressMessages(library(lubridate))
suppressMessages(library(sf))
suppressMessages(library(tmap))
suppressMessages(library(USAboundaries))
suppressMessages(library(rgeos))
suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))
suppressMessages(library(xts))
suppressMessages(library(raster))
suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))
suppressMessages(library(lme4))
suppressMessages(library(xtable))
suppressMessages(library(ggrepel))
suppressMessages(library(viridis))
suppressMessages(library(gridExtra))
```

The newest GIS shapefile contains missing geometries for more than 30% of the tornadoes. The number of missing geometries is highest after 1995. Instead here we use the csv file from https://www.spc.noaa.gov/wcm/#data  Use the start lon/lat and create a `sp` object then convert to `sf`. Set the coordinate reference system (crs) to ESPG 4326.
```{r, eval = FALSE}
Tor.spdf <- read.csv(file = "1950-2017_actual_tornadoes.csv")
sp::coordinates(Tor.spdf) <- ~ slon + slat
Tor.sfdf <- st_as_sf(Tor.spdf)
st_crs(Tor.sfdf) <- 4326
```

Remove tornadoes in Hawaii, Alaska, and Puerto Rico and those occurring before 1994. That year marks the beginning of comprehensive WSR-88D radar. For missing EF ratings use the modification rules (if/else) defined here: https://www.spc.noaa.gov/wcm/OneTor_F-scale-modifications.pdf
```{r, eval = FALSE}
All_Tornadoes <- Tor.sfdf %>%
  filter(yr >= 1994,
         !st %in% c("AK", "PR", "HI")) %>%
  mutate(mag = ifelse(mag == -9 & len <= 5, 0, mag),
         mag = ifelse(mag == -9 & len > 5, 1, mag))
```

Add a data/time column also add columns for path length, width, and area in metric units. Leave the time zone as native CDT. Create a convective day (6AM to 6AM) column taking hours 00:00:00 -> 05:59:59 and assigning it to the previous date (this associates the previous day's date to tornadoes occurring up to 6 hours after local midnight).
```{r, eval = FALSE}
All_Tornadoes <- All_Tornadoes %>%
  mutate(dy = format(as.Date(date,format="%m/%d/%y"), "%d"),
         DateTime = as.POSIXct(paste(yr, mo, dy, time), format = "%Y%m%d%H:%M:%S"),
         Hour = hour(DateTime),
         Year = year(DateTime),
         cDateTime = DateTime - as.difftime(6, unit = "hours"),
         cDate = as.Date(as_datetime(ifelse(Hour < 6, (DateTime - 86400), cDateTime), tz = Sys.timezone())),
         Length = len * 1609.34,
         Length = ifelse(Length == 0, min(Length[Length > 0]), Length), #takes care of zero length
         Width = wid * .9144,
         Width = ifelse(Width == 0, min(Width[Width > 0]), Width), #takes care of zero width
         Width = ifelse(Year >= 1995, Width * pi/4, Width), #takes care of change: avg to max
         cas = inj + fat,
         AreaPath = Length * Width,
         Ma = factor(month.abb[mo], levels = month.abb[1:12])) %>%
  sf::st_sf()
max(All_Tornadoes$yr)
```

The geometry type is `POINT`. Each tornado is represented as a single point location geometry (start location). 

Add power dissipation per tornado. Use the empirical model for tornado winds by EF rating taken from Table 3-1 of NRC 2007. Percent area by EF rating for each EF category. Threshold wind speeds (m/s) are a lower bound 3-sec gusts on the operational EF Scale (Table 2-1 of NRC2007). This is based on work by Fricker et al. (2017). The model is
$$
E = A_p \rho \sum_{j=0}^{J} w_j v_j^{3},
$$
where $A_p$ is the area of the path, $\rho$ is area density [1 kg/m^3]  $v_j$ is the midpoint wind speed for each rating, and $w_j$ is the corresponding fraction of path area by EF rating. With no upper bound on the EF5 wind speeds, the midpoint wind speed is set at 97 m~s$^{-1}$ (7.5 m~s$^{-1}$ above the threshold wind speed consistent with the EF4 midpoint speed relative to its threshold)
```{r, eval = FALSE}
perc <- c(1, 0, 0, 0, 0, 0, 
          .772, .228, 0, 0, 0, 0,
          .616, .268, .115, 0, 0, 0,
          .529, .271, .133, .067, 0, 0,
          .543, .238, .131, .056, .032, 0,
          .538, .223, .119, .07, .033, .017)
percM <- matrix(perc, ncol = 6, byrow = TRUE)
threshW <- c(29.06, 38.45, 49.62, 60.8, 74.21, 89.41)
midptW <- c(diff(threshW)/2 + threshW[-length(threshW)], threshW[length(threshW)] + 7.5)
ef <- All_Tornadoes$mag + 1
EW3 <- numeric()
for(i in 1:length(ef)) EW3[i] = midptW^3 %*% percM[ef[i], ]
All_Tornadoes <- All_Tornadoes %>%
  mutate(ED = EW3 * AreaPath)
```

Determine the distance between tornadoes in space and time. Use a projection, not lat/lon. See https://epsg.io/102004. Extract the coordinates of the start locations as a N by 2 matrix, where N is the number of tornadoes. Also extract the date-time as a vector of class `POSIXct`.
```{r, eval = FALSE}
All_Tornadoes <- st_transform(All_Tornadoes, crs = 102004)
space <- st_coordinates(All_Tornadoes)
time <- All_Tornadoes$DateTime
```

Next compute pairwise Euclidean distances in space and, separately, in time using the `dist()` function. Divide the spatial distance by 15 so that the values are commensurate with the time 'distance' based on the assumption of 15 meters per second (~34 mph) for an average speed of tornado-generating storms. 

Compare: Distance from New York to Denver is 2.622 x 10^6 meters. There are 3.154 x 10^7 seconds in a year. This will capture the historic multiday tornado outbreaks. For analysis we want to consider each day in the multiday group separately. As the value of the divisor increases cluster areas get larger. Remove `ds` and `dt` to free memory.
```{r, eval = FALSE}
ds <- dist(space) / 15
dt <- dist(time)
dst <- ds + dt
rm(ds, dt)
```

Distances are saved as an object of class `dist` containing a vector of length N * (N-1)/2, which is the number of unique point pairs.

Next group the tornadoes based on the space-time distances. This is done with the `hclust()` (hierarchical cluster) function. Initially, each tornado is assigned to its own group and then the algorithm joins the two closest tornadoes determined by values in `dst`. The algorithm continues by joining tornadoes (and tornado groups) until there is a single large group.

The single linkage method (`method = "single"`) is related to the minimal spanning tree (MST) and adopts a 'friends of friends' grouping strategy. An edge-weighted graph is a graph where each edge has a weight (or cost). Here weights are space-time distances between tornadoes. A MST of an edge-weighted graph is a spanning tree whose weight (the sum of the weights of its edges) is no larger than the weight of any other spanning tree. A spanning tree of a graph on N vertices (tornado centroids) is a subset of N-1 edges that form a tree (Skiena 1990, p. 227).
 
The `cutree()` function is used to extract a group number for each tornado. Tornadoes in each group are close in space & time. Here the tree is cut at a height of 50000 space-time units. Making `h` smaller results in smaller groups (fewer tornadoes per group).
```{r, eval = FALSE}
stime <- proc.time()
tree <- hclust(dst, method = "single")
groupNumber <- as.integer(cutree(tree, h = 50000))
proc.time() - stime
```

Add the group number to each tornado. 
```{r, eval = FALSE}
All_Tornadoes$groupNumber <- groupNumber
```

Compute group-level statistics. Keep only tornado groups with at least 30 tornadoes.
```{r, eval = FALSE}
Groups.sfdfT <- All_Tornadoes %>%
  group_by(groupNumber) %>%
  summarize(Year = first(Year),
            Month = first(mo),
            FirstDate = first(date),
            LastDate = last(date),
            Name = paste(FirstDate, "to", LastDate),
            FirstcDate = first(cDate),
            LastcDate = last(cDate),
            ncD = n_distinct(cDate),
            nT = n(),
            n0 = sum(mag == 0),
            n1 = sum(mag == 1),
            n2 = sum(mag == 2),
            n3 = sum(mag == 3),
            n4 = sum(mag == 4),
            n5 = sum(mag == 5),
            GroupTotalED = sum(ED),
            Name2 = paste(round(GroupTotalED/10^12), "TW"),
            maxEF = max(mag),
            nD = n_distinct(date),
            StartTime = first(DateTime),
            EndTime = last(DateTime),
            Duration = difftime(EndTime, StartTime, units = "secs"), 
            cas = sum(inj + fat)) %>%
  filter(nT >= 30)
dim(Groups.sfdfT)
```
There are 6156 Groups and 155 large groups.

Get the tornadoes that are in the 155 large groups. 
```{r, eval = FALSE}
GroupTornadoes <- All_Tornadoes %>%
  filter(groupNumber %in% Groups.sfdfT$groupNumber)
```

############################
## Forbes 2004 Comparison ##
############################

Over the period 1994-2017 there were 155 tornado groups with at least 30 tornadoes. How many of these groups are not considered `outbreaks`? How many previously considered `outbreaks` are missed by this algorithm?
```{r, eval = FALSE}
#FUHRMANN 2014
Groups.sfdfT %>%
  filter(Year <= 2011) %>%
  top_n(n = 9, wt = nT) %>%
  arrange(desc(nT))

Groups.sfdfT %>%
  filter(Year <= 2011) %>%
  top_n(n = 9, wt = GroupTotalED) %>%
  arrange(desc(GroupTotalED))

#FORBES 2004
Groups.sfdfT %>%
  filter(Year <= 2004) %>%
  top_n(n = 13, wt = nT) %>%
  arrange(desc(nT))

Groups.sfdfT %>%
  filter(Year <= 2004) %>%
  top_n(n = 13, wt = GroupTotalED) %>%
  arrange(desc(GroupTotalED))
```

```{r, eval = FALSE}
Groups.fpfn <- Groups.sfdfT %>%
  filter(Year <= 2011)

Groups.fpfn %>%
  top_n(n = 9, wt = nT) %>%
  arrange(desc(nT))
```

False Positive: How many outbreaks Schroder and Elsner identified, not identified by Forbes/Fuhrmann
False Negative: How many Forbes/Fuhrmann picked up that we did not
% Match: F match Z / sum(F & Z )
```{r, eval = FALSE}
FPFN <- read.csv("FPFN_Forbes.csv")
FPFN <- FPFN[1:8,]
FPFN
```

Graph of the percent match values between ours and the Forbes 2004. 
```{r, eval = FALSE}
ggplot(FPFN, aes(x = Cuttree, y = PercentMatch)) + 
  geom_line(size = 1.5) +
  geom_point(size = 2) +
  labs(x = "Space - Time Distance", 
       y = "Percent") +
  theme_minimal() +
  theme(text = element_text(size=25)) +
#    ggtitle("Relationship between Space-Time Units and Tornado Group Match") + 
#  theme(plot.title = element_text(hjust = 0.5)) +
   
#  scale_x_continuous(breaks = round(seq(min(FPFN$Cuttree), 
 #                                       max(FPFN$Cuttree), 
  #                                      by = 15000), 1)) + 
  ylim(0,100)
```

########################################
## Extract Big Days from Large Groups ##
########################################

Filter individual tornadoes to remove those that are not part of a large group. Group by group number and convective dates. Remove days within big groups (group days) having fewer than 10 tornadoes.
```{r, eval = FALSE}
BigDays.sfdfT <- All_Tornadoes %>%
  filter(groupNumber %in% Groups.sfdfT$groupNumber) %>%
  group_by(groupNumber, cDate) %>%
  summarize(nT = n(),
            n0 = sum(mag == 0),
            n1 = sum(mag == 1),
            n2 = sum(mag == 2),
            n3 = sum(mag == 3),
            n4 = sum(mag == 4),
            n5 = sum(mag == 5),
            GroupDayTotalED = sum(ED),
            GroupDayMaxED = max(ED),
            GroupDayMeanED = mean(ED),
            GroupDayCas = sum(cas),
            GroupDayFat = sum(fat),
            StartTime = first(DateTime),
            EndTime = last(DateTime)) %>%
  filter(nT >= 10) %>%
  mutate(Year = year(cDate),
         Mo = month(cDate),
         Month = format(cDate, "%m"), # this is needed to preserve the leading zeros
         Day = format(cDate, "%d"), 
         ATP = GroupDayTotalED/10^12)                                                                                      
dim(BigDays.sfdfT)
```
There are 212 big days in large groups. These will be used for further analysis and modeling.

What is the percentage of all big days (>= 10 tornadoes) that occur within a big group?
```{r, eval = FALSE}
TotalBigDays <- All_Tornadoes %>%
  group_by(groupNumber, cDate) %>%
  summarize(nT = n()) %>%
  filter(nT >= 10)

dim(BigDays.sfdfT)[1]/dim(TotalBigDays)[1] * 100
```
29% of all big days (>= 10 tornadoes) occur within a big group/outbreak (>= 30 tornadoes)

Create a unique ID for each big day and each tornado. Extract the tornadoes associated with each big day using the unique ID. 
```{r, eval = FALSE}
BigDayTornadoes <- All_Tornadoes %>%
   mutate(ID = paste0(gsub("-", "", cDate), groupNumber))
BigDays.sfdfT <- BigDays.sfdfT %>%
   mutate(ID = paste0(gsub("-", "", cDate), groupNumber))

BigDayTornadoes <- BigDayTornadoes %>%
  filter(ID %in% BigDays.sfdfT$ID)

sum(BigDays.sfdfT$nT)
```

################################
## Part 2: Environmental data ##
################################

## Get the NARR time

Convert `StartTime` and `EndTime` to UTC.
```{r, eval = FALSE}
attr(BigDays.sfdfT$StartTime, "tzone") <- "UTC"
attr(BigDays.sfdfT$EndTime, "tzone") <- "UTC"
```

Round the UTC time to nearest 6 hours. This is done with the `align.time()` function from the **xts** package. Adjust it by 3 hours to get the closest time. This falls within the outbreak so you need to subtract by 3 hours (10800 seconds). This will produce the closest 3 hour NARR time that occurs before and not within the big day. 
```{r, eval = FALSE}
BigDays.sfdfT$NARRtime <- (align.time(BigDays.sfdfT$StartTime, n = (60 * 60 * 3)) - 3600 * 3)
```

Split the NARR date and time into their individual variables. Then bind the columns for BigDays.sfdfT. NOTE: cannot do a mutate because 00Z produces NAs.
```{r, eval = FALSE}
NARRday = format(as.POSIXct(strptime(BigDays.sfdfT$NARRtime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%Y/%m/%d")
NARRZtime = format(as.POSIXct(strptime(BigDays.sfdfT$NARRtime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%H")

BigDays.sfdfT <- cbind(BigDays.sfdfT, NARRday, NARRZtime)
```

Create a table to show how many big days fall in each start Z time. 
```{r, eval = FALSE}
BigDays.sfdfT %>%
  group_by(NARRZtime) %>%
  summarize(count = n())
```
** Table 3: Total number of big days associated with each Z time. **



Create a downloadable string of information for the varying NARR times. 
```{r, eval = FALSE}
BigDays.sfdfT <- BigDays.sfdfT %>%
  mutate(YrMoDa = gsub("/", "", NARRday),
         slug = paste0("merged_AWIP32.",YrMoDa, NARRZtime),
         slug2 = paste0("merged_AWIP32.",YrMoDa))
```

Extract a vector of the big days. Save as a .csv for NARR download. 
```{r, eval = FALSE}
bigdays <- BigDays.sfdfT$NARRday
bigdaytimes <- BigDays.sfdfT$NARRZtime
x <- cbind(as.character(bigdays), as.character(bigdaytimes))
write.csv(x, "BigDays.csv")
```

Obtain the group day hulls. Transform the CRS to match that of the environmental data raster grids.
```{r, eval = FALSE}
BigDays.sfdfT <- st_convex_hull(BigDays.sfdfT)
BigDays.sfdfT$HullArea <- st_area(BigDays.sfdfT)
BigDays.sfdfT <- st_transform(BigDays.sfdfT, 
  crs = "+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")
```

Get the centroid (central point of the tornado activity) for each big day. 
```{r, eval = FALSE}
BigDayCentroids.df <- st_centroid(BigDays.sfdfT)
BigDayCentroids.df$groupArea <- st_area(st_convex_hull(BigDays.sfdfT))
BigDayCentroids.df$groupDensity <- BigDayCentroids.df$nT/BigDayCentroids.df$groupArea
```

## Download NARR data: 

Data is downloaded from NCAR's North American Regional Reanalysis (https://rda.ucar.edu/datasets/ds608.0/#!access). It extends from 1-1-1979 to 11-1-2018. Use the NCAR NARR 3-hourly files.  

Spatial Extent: 
Longitude Range: Westernmost = 148.64E Easternmost = 2.568W
Latitude Range: Southernmost = 0.897N Northernmost = 85.333N

```{r, eval = FALSE}
BigDays.sfdfT <- st_transform(BigDays.sfdfT, 
  crs = "+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")
```

The list of all variables can be found here: http://www.emc.ncep.noaa.gov/mmb/rreanl/merged_land_AWIP32.pdf 

```{r, eval = FALSE}
slug <- BigDays.sfdfT$slug
slug2 <- BigDays.sfdfT$slug2
```

Read the grib files as raster bricks and assign the CAPE and helicity variables to separate raster layers. Extract the average (and extreme) environmental values within each of the big days in large groups hulls.
```{r, eval = FALSE}
avgCAPE <- numeric()
avgHLCY <- numeric()
avgCIN <- numeric()
avgUSTM <- numeric()
avgVSTM <- numeric()
avgBS <- numeric()
avgSM <- numeric()
avgRATIO <- numeric()
maxCAPE <- numeric()
maxHLCY <- numeric()
minCIN <- numeric()
maxUSTM <- numeric()
maxVSTM <- numeric()
maxBS <- numeric()
maxSM <- numeric()
 
for(i in 1:length(slug)){
  print(i)
  rb <- brick(paste0("/Volumes/My Passport for Mac/NCARNARR/All/", BigDays.sfdfT$slug2[i], "/",BigDays.sfdfT$slug[i])) #<-- this is for varying NARR times
  CAPE <- raster(rb, layer = 375)
  HLCY <- raster(rb, layer = 323)
  CIN <- raster(rb, layer = 376)
  USTM <- raster(rb, layer = 324)
  VSTM <- raster(rb, layer = 325)
  UGRD500 <- raster(rb, layer = 117) 
  VGRD500 <- raster(rb, layer = 118) 
  UGRDsfc <- raster(rb, layer = 293) 
  VGRDsfc <- raster(rb, layer = 294)     
  SM <- sqrt(USTM^2 + VSTM^2)
  RATIO <- CAPE/abs(CIN)
  BS <- sqrt(((UGRD500 - UGRDsfc)**2) + ((VGRD500 - VGRDsfc)**2))
  avgCAPE <- c(avgCAPE, as.numeric(raster::extract(CAPE, BigDays.sfdfT[i, ], fun = mean)))
  avgHLCY <- c(avgHLCY, as.numeric(raster::extract(HLCY, BigDays.sfdfT[i, ], fun = mean)))
  avgCIN <- c(avgCIN, as.numeric(raster::extract(CIN, BigDays.sfdfT[i, ], fun = mean)))
  avgUSTM <- c(avgUSTM, as.numeric(raster::extract(USTM, BigDays.sfdfT[i, ], fun = mean)))
  avgVSTM <- c(avgVSTM, as.numeric(raster::extract(VSTM, BigDays.sfdfT[i, ], fun = mean)))
  avgSM <- c(avgSM, as.numeric(raster::extract(SM, BigDays.sfdfT[i, ], fun = mean)))
  avgRATIO <- c(avgRATIO, as.numeric(raster::extract(RATIO, BigDays.sfdfT[i, ], fun = mean)))
  avgBS <- c(avgBS, as.numeric(raster::extract(BS, BigDays.sfdfT[i, ], fun = mean)))
  maxCAPE <- c(maxCAPE, as.numeric(raster::extract(CAPE, BigDays.sfdfT[i, ], fun = max)))
  maxHLCY <- c(maxHLCY, as.numeric(raster::extract(HLCY, BigDays.sfdfT[i, ], fun = max)))
  minCIN <- c(minCIN, as.numeric(raster::extract(CIN, BigDays.sfdfT[i, ], fun = min)))
  maxUSTM <- c(maxUSTM, as.numeric(raster::extract(USTM, BigDays.sfdfT[i, ], fun = max)))
  maxVSTM <- c(maxVSTM, as.numeric(raster::extract(VSTM, BigDays.sfdfT[i, ], fun = max)))
  maxSM <- c(maxSM, as.numeric(raster::extract(SM, BigDays.sfdfT[i, ], fun = max)))
  maxBS <- c(maxBS, as.numeric(raster::extract(BS, BigDays.sfdfT[i, ], fun = max)))
}
```

Add environmental data values to the group day means data frame.
```{r, eval = FALSE}
BigDays.sfdfT$avgCAPE <- avgCAPE
BigDays.sfdfT$avgHLCY <- avgHLCY
BigDays.sfdfT$avgCIN <- avgCIN
BigDays.sfdfT$avgUSTM <- avgUSTM
BigDays.sfdfT$avgVSTM <- avgVSTM
BigDays.sfdfT$avgBS <- avgBS
BigDays.sfdfT$avgRATIO <- avgRATIO
BigDays.sfdfT$avgSM <- avgSM
BigDays.sfdfT$maxCAPE <- maxCAPE
BigDays.sfdfT$maxHLCY <- maxHLCY
BigDays.sfdfT$minCIN <- minCIN
BigDays.sfdfT$maxUSTM <- maxUSTM
BigDays.sfdfT$maxVSTM <- maxVSTM
BigDays.sfdfT$maxBS <- maxBS
BigDays.sfdfT$maxSM <- maxSM
```

Scale the variables to make them easier to read and input for models. 
```{r, eval = FALSE}
BigDays.sfdfT$avgCAPE2 <- BigDays.sfdfT$avgCAPE/1000
BigDays.sfdfT$avgHLCY2 <- BigDays.sfdfT$avgHLCY/100
BigDays.sfdfT$avgCIN2 <- BigDays.sfdfT$avgCIN/100
BigDays.sfdfT$avgBS2 <- BigDays.sfdfT$avgBS/10
BigDays.sfdfT$avgUSTM2 <- BigDays.sfdfT$avgUSTM/10
BigDays.sfdfT$avgVSTM2 <- BigDays.sfdfT$avgVSTM/10
BigDays.sfdfT$avgSM2 <- BigDays.sfdfT$avgSM/10

BigDays.sfdfT$maxCAPE2 <- BigDays.sfdfT$maxCAPE/1000
BigDays.sfdfT$maxHLCY2 <- BigDays.sfdfT$maxHLCY/100
BigDays.sfdfT$minCIN2 <- BigDays.sfdfT$minCIN/100
BigDays.sfdfT$maxBS2 <- BigDays.sfdfT$maxBS/10
BigDays.sfdfT$maxUSTM2 <- BigDays.sfdfT$maxUSTM/10
BigDays.sfdfT$maxVSTM2 <- BigDays.sfdfT$maxVSTM/10
BigDays.sfdfT$maxSM2 <- BigDays.sfdfT$maxSM/10
```

Save `BigDays.sfdfT` so we can work on the models below without needing to run all the code above.
```{r}
#save(BigDays.sfdfT, BigDayTornadoes, Groups.sfdfT, GroupTornadoes, All_Tornadoes, file = "BigDays.RData")
load("BigDays.RData")
dim(BigDays.sfdfT)
```

######################
## Group Statistics ##
######################

Make tables: Top 10 tornado groups by number of tornadoes, power dissipation, and duration.
```{r, eval = FALSE}
Groups.sfdfT %>%
  top_n(n = 10, wt = nT) %>%
  arrange(desc(nT))

Groups.sfdfT %>%
  top_n(n = 10, wt = GroupTotalED) %>%
  arrange(desc(GroupTotalED))

Groups.sfdfT %>%
  top_n(n = 10, wt = Duration) %>%
  arrange(desc(Duration))

Groups.sfdfT %>%
  top_n(n = 10, wt = nD) %>%
  arrange(desc(nD))
```

Map the locations (start points) of the top 25 tornado groups by power dissipation. First select the top 25 groups by total ED. Then create a simple features data frame using only the tornadoes in these groups by filtering on group number. Arrange by ascending ED. Also arrange by EF so the most damaging tornadoes (higher EF rating) are placed on the plot after the least damaging tornadoes.
```{r, eval = FALSE}
Top25BigDays <- as.data.frame(Groups.sfdfT) %>%
  top_n(n = 25, wt = GroupTotalED) %>%
  arrange(GroupTotalED)

sfdf <- BigDayTornadoes %>%
   filter(groupNumber %in% Top25BigDays$groupNumber) %>%
   mutate(EF = factor(mag))

sfdf2 <- left_join(sfdf, Top25BigDays, by = "groupNumber") %>%
  arrange(GroupTotalED, EF)
```

Get state borders and use the `tm_shape()` function.
```{r, eval = FALSE}
sts <- state.name[!state.name %in% c("Alaska", "Hawaii")]
stateBorders <- us_states(states = sts)

tm_shape(stateBorders) + 
  tm_borders(col = "grey") +
  tm_layout(legend.outside = TRUE) +
tm_shape(sfdf2) +
  tm_facets(by = "GroupTotalED", ncol = 5)  +
  tm_symbols(col = "EF", palette = "Reds", n = 6, alpha = .6, border.lwd = 0) +
  tm_layout(panel.labels = paste(BigDays.sfdfT$Name2, BigDays.sfdfT$Name), panel.label.size = 1.3, panel.label.bg.color = "grey90") 
```

Distribution of the number of days each group lasts.
```{r, eval = FALSE}
dfnD <- as.data.frame(Groups.sfdfT) %>%
  arrange(desc(nD))
table(dfnD$nD)
(151-46)/151 * 100 

dfnD <- as.data.frame(Groups.sfdfT) %>%
  arrange(desc(Year))
table(dfnD$Year)

as.data.frame(Groups.sfdfT) %>%
  group_by(nD) %>%
  summarize(tot_events = n(),
            tot_torn = sum(nT))
```
** Table 1: The total number of large groups and tornadoes by duration. **
There are 46 groups lasting only one day, 81 groups lasting two days, etc. 69% of the groups are multi-day events.

Frequency by month of the start day of multi-day groups of at least three days in length.
```{r, eval = FALSE}
as.data.frame(Groups.sfdfT) %>%
  filter(nD >= 3) %>%
  count(Month) %>%
  mutate(prop = prop.table(n))

as.data.frame(Groups.sfdfT) %>%
  count(Month, nD) %>%
  mutate(prop = prop.table(n))
```

Extract the geographic centroids of tornado genesis on big tornado days by creating an `sf` object using `st_centroid()` that reduces the MULTIPOINT geometry to a POINT geometry. Compute the area of the group and the number of tornadoes per area (density).
```{r}
groupDayCentroids.sfdfT <- st_centroid(BigDays.sfdfT)
groupDayCentroids.sfdfT$groupArea <- st_area(st_convex_hull(BigDays.sfdfT))
groupDayCentroids.sfdfT$groupDensity <- groupDayCentroids.sfdfT$nT/groupDayCentroids.sfdfT$groupArea
```

Obtain the group day hulls. Transform the CRS to match that of the environmental data raster grids.
```{r, eval = FALSE}
BigDays.sfdfT <- st_convex_hull(BigDays.sfdfT)
BigDays.sfdfT$HullArea <- st_area(BigDays.sfdfT)
BigDays.sfdfT <- st_transform(BigDays.sfdfT, 
  crs = "+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")
```

Map of the longest tornado outbreak. Tornado points colored by cDate. 

```{r, eval = FALSE}
longestgroup <- Groups.sfdfT %>%
  filter(groupNumber == 3075)
longestgroup <- st_convex_hull(longestgroup)

#longestdays <- BigDays.sfdfT %>%
 # filter(groupNumber == 3075)

longestdaytorns <- GroupTornadoes %>%
  filter(groupNumber == 3075)
```


```{r, eval = FALSE}
states.sf <- us_states()
counties.sf <- us_counties()

tm_shape(stateBorders) + 
  tm_borders(col = "gray15", alpha = 1) +
  tm_layout(legend.bg.color = "white", legend.text.size = .75) +
tm_shape(counties.sf) +
  tm_borders(col = "gray40", alpha = .3) +
tm_shape(longestgroup, projection = "merc", is.master = TRUE) + 
  tm_borders(col = "gray15", alpha = 1, lwd = 5) +
  tm_scale_bar(width = .75, size = 1.25, lwd = 2) +
  tm_compass(size = 5, lwd = 2, fontsize = 1) + 
    tm_format("World", legend.position = c("left", "top"),
                    attr.position = c("left", "top"),
                   legend.frame = FALSE,
                   #title = "Longest Group of Tornadoes",
                   #title.size = 1.3,
                   #title.position = c("left", "TOP"),
                   inner.margins = c(.1, .3, .15, .3)) +
  tm_layout(legend.bg.color = "white", legend.text.size = .75) +
tm_shape(longestdaytorns, title = "Day") +
  tm_symbols(size = 3, col = "cDate", n = 5, palette = "BuPu", title.col = "Day") + 
  tm_layout(legend.title.size = 1.5,
            legend.position = c("right", "bottom"), 
            legend.stack = "horizontal",
            legend.frame = FALSE, 
            legend.text.size = 1.5, legend.width = -0.35)
```
**Figure 1: The September 4 – 8, 2004 event has the longest duration of all tornado groups. The black line is the hull (spatial extent) of the entire group. Each dot is colored by a different big day. **  
  
##################
# Stats and Maps #
##################

Top 10 Big Tornado Days: 
```{r, eval = FALSE}
BigDays.sfdfT %>%
  top_n(n = 10, wt = nT) %>%
  arrange(desc(nT))
```
** Table 2: The top ten big days in the largest tornado groups. ATP is the accumulated tornado power on a big day. **

Pecentage of all casualties and fatalities occurring on the big days in the large groups.
```{r, eval = FALSE}
sum(BigDays.sfdfT$GroupDayCas)/sum(All_Tornadoes$cas) * 100
sum(BigDays.sfdfT$GroupDayFat)/sum(All_Tornadoes$fat) * 100
```

Table the number of days per group. Also look at the day counts by year and month.
```{r, eval = FALSE}
table(table(BigDays.sfdfT$groupNumber))
table(BigDays.sfdfT$Year)
table(BigDays.sfdfT$Month)

#Peak Season: 
((50 + 56 + 23)/ 212) *100
```

61% of all big days in large groups occur during April, May, and June.

Create a map showing the frequency of big tornado days by county. First transform the CRS of the county boundaries to match the CRS of `BigDays.sfdfT`.
```{r, eval = FALSE}
counties.sf <- st_transform(counties.sf, 
                            crs = st_crs(BigDays.sfdfT))

stateBorders <- st_transform(stateBorders, 
                            crs = st_crs(BigDays.sfdfT))
```

Extract the Hull, centroids, and tornadoes for the May 30, 2004 big day. 

```{r, eval = FALSE}
May30 <- BigDays.sfdfT %>%
  filter(cDate == "2004-05-30")
May30 <- st_convex_hull(May30)

May30centroid <- groupDayCentroids.sfdfT %>%
  filter(cDate == "2004-05-30")

May30tornadoes <- BigDayTornadoes %>% 
  filter(groupNumber == May30centroid$groupNumber)
```

Make a map of the May 30 tornado day. Obtain the state and county boundaries from the **USAboundaries** package. 
```{r, eval = FALSE}
tm_shape(stateBorders) + 
  tm_borders(col = "gray15", alpha = 1) +
  tm_scale_bar(width = .75, size = 1.25, lwd = 2) +
  tm_compass(size = 5, fontsize = 1) + 
  tm_layout(legend.bg.color = "white", legend.text.size = .75) +
tm_shape(counties.sf) +
  tm_borders(col = "gray40", alpha = .3) +
  tm_scale_bar(width = 8, size = 8) +
  tm_format("World", legend.position = c("right", "top"),
                   attr.position = c("right", "top"),
                   legend.frame = FALSE,
                   #title = "May 30th Tornado Group",
                   #title.size = 1.3,
                   #title.position = c("left", "TOP"),
                   inner.margins = c(.2, .2, .2, .2)) +
tm_shape(May30, is.master = TRUE, projection = "merc") +
  tm_borders(col = "black", lwd = 3) +
tm_shape(May30tornadoes, col = "Hour") +
  tm_symbols(size = 3, col = "Hour", breaks = c(0, 6, 12, 18, 24), palette = "Reds") +
    tm_layout(legend.title.size = 1.5,
            legend.position = c("right", "bottom"), 
            legend.stack = "horizontal",
            legend.frame = FALSE, 
            legend.text.size = 1.25, legend.width = -0.3) +
tm_shape(May30centroid) +
  tm_symbols(size = 1.25, col = "black", shape = 24) 
```
** Figure 2: May 30, 2004, is a big tornado day characterized by 88 tornadoes. Each dot represents a tornado genesis location and is colored by the hour of the tornado. The black triangle is the geographic center of the genesis location. The black line defines the minimum convex polygon around the genesis locations (convex hull).**

```{r, eval = FALSE}
BigDays.sfdfT %>%
  top_n(n = 3, wt = -ATE) %>%
  arrange(desc(ATE))

BigDays.sfdfT %>%
  top_n(n = 3, wt = -ATE) %>%
  arrange(desc(ATE))
```
**Table 4: The maximum and minimum values associated with each big day. The top 3 rows represent the top three big days sorted by the number of tornadoes. The bottom three rows are the bottom 3 big days by the number of tornadoes. **

```{r}
BigDays.sfdfT <- BigDays.sfdfT %>%
 mutate(ID = paste0(gsub("-", "", cDate), groupNumber))
```

May 6, 2003 Big Day
```{r}
May6 <- BigDays.sfdfT %>%
  filter(ID == "200305062624")
May6 <- st_convex_hull(May6)

May6centroid <- groupDayCentroids.sfdfT %>%
  filter(ID == "200305062624")

May6tornadoes <- BigDayTornadoes %>% 
  filter(ID == "200305062624")
```

Plot the CAPE, HLCY, and CIN for the April 27, 2011 Big Day. First, read in the raster. 
```{r}
 rb <- brick(paste0("/Users/zoeschroder/Desktop/Projects/Tor-clusters/merged_AWIP32.20030506/merged_AWIP32.2003050612")) #<-- this is for varying NARR times
  CAPE <- raster(rb, layer = 375)
  HLCY <- raster(rb, layer = 323)
  CIN <- raster(rb, layer = 376)
  UGRD500 <- raster(rb, layer = 117) 
  VGRD500 <- raster(rb, layer = 118) 
  UGRDsfc <- raster(rb, layer = 293) 
  VGRDsfc <- raster(rb, layer = 294)     
  BS <- sqrt(((UGRD500 - UGRDsfc)**2) + ((VGRD500 - VGRDsfc)**2))
```

Project and transform the raster. Extract the environmental variables to the hull of the big day. 
```{r}
CAPE_May6 <- crop(CAPE, extent(May6))
CAPE_extent<- mask(CAPE_May6, May6)
plot(CAPE_extent)

maxCAPE <- which.max(CAPE_extent) #Returns a pixel number

#Test that this max value equals the one in BigDays.sfdfT
test <- getValues(CAPE_extent) 
test<-as.matrix(test, ncol=1)
```

Extract the maximum value of the CAPE raster for this big day. 
```{r}
CAPEmaxpos <- xyFromCell(CAPE_extent, maxCAPE)

xy <- data.frame(CAPEmaxpos)
CAPE_latlon <- data.frame(lon=xy$x, lat=xy$y)
print(CAPE_latlon)

CAPE_latlon <- SpatialPoints(CAPE_latlon)
proj4string(CAPE_latlon) = CRS("+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")
```

Plot the CAPE, centroid, and max value point in a raster. 
```{r}
counties <- us_counties()
states <- us_states()
```

```{r, eval = FALSE}
p1 <- tm_shape(CAPE_extent) +
  tm_raster(title = "",  n = 6, palette = "Reds") +
  tm_format(title = expression(paste("CAPE [J ", kg^-1, "]")), "World", legend.position = c("right", "bottom"),
                   attr.position = c("right", "bottom"),
                   legend.frame = FALSE,
                   inner.margins = c(.1, 0, .1, .18), #bottom, left, top
                    legend.text.size = 1.3, legend.width = -0.28, legend.title.size=1.5, legend.bg.color = "white", title.size = 2) +
#tm_shape(counties) +
  #tm_borders(col = "grey") +
  tm_scale_bar(width = 0.3, size = 1.3, position = c("right", "top"), color.dark = "gray70") +
tm_shape(states) +
  tm_borders() +
tm_shape(May6, is.master = TRUE, projection = "merc") +
  tm_borders(col = "black", lwd = 3)  +
#tm_shape(May6centroid) +
#  tm_symbols(size = 1.25, col = "black", shape = 24) +
tm_shape(CAPE_latlon) + 
  tm_symbols(size = 1.4, col = "black", shape = 22)
p1
```

```{r}
HLCY_May6 <- crop(HLCY, extent(May6))
HLCY_extent<- mask(HLCY_May6, May6)
plot(HLCY_extent)

maxHLCY <- which.max(HLCY_extent)
```

Extract the maximum value of the HLCY raster for this big day. 
```{r}
HLCYmaxpos <- xyFromCell(HLCY_extent, maxHLCY)

xy <- data.frame(HLCYmaxpos)
HLCY_latlon <- data.frame(lon=xy$x, lat=xy$y)
print(HLCY_latlon)

HLCY_latlon <- SpatialPoints(HLCY_latlon)
proj4string(HLCY_latlon) = CRS("+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")
```

```{r, eval = FALSE}
p2 <- tm_shape(HLCY_extent) +
  tm_raster(title = "", n = 5, palette = "Blues") + #"YlGnBu") +
  tm_format(title = expression(paste("HLCY [",m^2, s^-2, "]")), "World", legend.position = c("right", "bottom"),
                   attr.position = c("right", "bottom"),
                   legend.frame = FALSE,
                   inner.margins = c(.1, 0, .1, .15), #bottom, left, top
                    legend.text.size = 1.3, legend.width = -0.25, legend.title.size=1.5, legend.bg.color = "white", title.size = 2) +
#tm_shape(counties) +
#  tm_borders(col = "grey") +
  tm_scale_bar(width = 0.3, size = 1.3, position = c("right", "top"), color.dark = "gray70") +
tm_shape(states) +
  tm_borders() +
tm_shape(May6, is.master = TRUE, projection = "merc") +
  tm_borders(col = "black", lwd = 3)  +
#tm_shape(May6centroid) +
#  tm_symbols(size = 1.25, col = "black", shape = 24) +
tm_shape(HLCY_latlon) + 
  tm_symbols(size = 1.4, col = "black", shape = 22)
p2
```

```{r}
CIN_May6 <- crop(CIN, extent(May6))
CIN_extent<- mask(CIN_May6, May6)
plot(CIN_extent)

minCIN <- which.min(CIN_extent)
```

Extract the maximum value of the CIN raster for this big day. 
```{r}
CINminpos <- xyFromCell(CIN_extent, minCIN)

xy <- data.frame(CINminpos)
CIN_latlon <- data.frame(lon=xy$x, lat=xy$y)
print(CIN_latlon)

CIN_latlon <- SpatialPoints(CIN_latlon)
proj4string(CIN_latlon) = CRS("+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")
```

```{r, eval = FALSE}
p3 <- tm_shape(CIN_extent) +
  tm_raster(title = "", n =5, palette = "Greens") + #"YlOrBr") +
  tm_format(title = expression(paste("CIN [J ", kg^-1, "]")), "World", legend.position = c("right", "bottom"),
                   attr.position = c("right", "bottom"),
                   legend.frame = FALSE,
                   inner.margins = c(.1, 0, .1, .15), #bottom, left, top
                    legend.text.size = 1.3, legend.width = -0.25, legend.title.size=1.5, legend.bg.color = "white", title.size = 2) +
#tm_shape(counties) +
#  tm_borders(col = "grey") +
  tm_scale_bar(width = 0.3, size = 1.3, position = c("right", "top"), color.dark = "gray70") +
tm_shape(states) +
  tm_borders() +
tm_shape(May6, is.master = TRUE, projection = "merc") +
  tm_borders(col = "black", lwd = 3)  +
#tm_shape(May6centroid) +
#  tm_symbols(size = 1.25, col = "black", shape = 24) +
tm_shape(CIN_latlon) + 
  tm_symbols(size = 1.4, col = "black", shape = 22)
p3
```

```{r}
BS_May6 <- crop(BS, extent(May6))
BS_extent<- mask(BS_May6, May6)
plot(BS_extent)

maxBS <- which.max(BS_extent)
```

Extract the maximum value of the BS raster for this big day. 
```{r}
BSmaxpos <- xyFromCell(BS_extent, maxBS)

xy <- data.frame(BSmaxpos)
BS_latlon <- data.frame(lon=xy$x, lat=xy$y)
print(BS_latlon)

BS_latlon <- SpatialPoints(BS_latlon)
proj4string(BS_latlon) = CRS("+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")
```

```{r, eval = FALSE}
p4 <- tm_shape(BS_extent) +
  tm_raster(title = "", n = 5, palette = "Purples") +
  tm_format(title = expression(paste("BS [m ", s^-1, "]")), "World", legend.position = c("right", "bottom"),
                   attr.position = c("right", "bottom"),
                   legend.frame = FALSE,
                   inner.margins = c(.1, 0, .1, .15), #bottom, left, top
                    legend.text.size = 1.3, legend.width = -0.2, legend.title.size=1.5, legend.bg.color = "white", title.size = 2) +
#tm_shape(counties) +
#  tm_borders(col = "grey") +
  tm_scale_bar(width = 0.3, size = 1.3, position = c("right", "top"), color.dark = "gray70") +
tm_shape(states) +
  tm_borders() +
tm_shape(May6, is.master = TRUE, projection = "merc") +
  tm_borders(col = "black", lwd = 3)  +
#tm_shape(May6centroid) +
#  tm_symbols(size = 1.25, col = "black", shape = 24) +
tm_shape(BS_latlon) + 
  tm_symbols(size = 1.4, col = "black", shape = 22)
p4
```

Combine into one figure: 
```{r}
tmap_arrange(p1, p2, p3, p4, ncol = 2, nrow = 2)
```

Plot the centroid for each group day and size the aesthetic by the number of tornadoes.
```{r}
tm_shape(stateBorders) + 
  tm_borders(col = "gray15", alpha = 1) +
  tm_compass(size = 5, position = c("left", "bottom"), fontsize = 1) + tm_scale_bar(width = 0.6, size = 1.5) +
tm_shape(counties.sf) +
  tm_borders(col = "gray40", alpha = .3) +
  tm_compass(position = c("left", "bottom")) + 
  tm_scale_bar(width = 8, size = 8) +
  tm_format("World",
                   #title = "Big Day Centroids",
                   #title.size = 1.3,
                   #title.position = c("left", "TOP"),
                   inner.margins = c(.15, .1, .1, .05)) +
tm_shape(groupDayCentroids.sfdfT, is.master = TRUE, projection = "merc") +
  tm_symbols(col = "nT", n = 4, 
             palette = c("lightsalmon", "salmon3", "red", "red4"), legend.col.show = FALSE,
             size = "nT",
             shape =24, 
             scale = 3, legend.size.show = FALSE) + 
  tm_add_legend("symbol", title = "Total Tornadoes", shape = 24,
                col = c("lightsalmon", "salmon3", "red", "red4"), 
                size = c(.75, 1, 1.25, 1.5), 
                labels = c("0 to 50", "50 to 100", "100 to 150", "150 to 200")) +
  tm_layout(legend.title.size=1.75, 
            legend.text.size = 1.5,
            legend.position = c("right","top"),
            legend.stack = "horizontal",
            legend.bg.color = "white",
            legend.frame = FALSE, 
            legend.width = -0.3, 
            legend.height = -0.3)
``` 

** Figure 3: Centroids of genesis locations occurring on big days in large groups. The triangles are sized by the number of tornadoes on that day. **

Time series graphs
```{r}
groupDayCentroids.sfdfT %>%
  group_by(Year) %>%
  summarize(avgArea = mean(groupArea)) %>%
  ggplot(., aes(x = Year, y = as.numeric(avgArea) / 10^10)) +
    scale_y_continuous(limits = c(0, NA)) +
    scale_x_continuous(breaks = seq(1995, 2015, 5)) +
    geom_point() +
    geom_smooth(method = lm) +
    ylab("Group Area [100 x 100 sq. km]") +
    theme_minimal()

groupDayCentroids.sfdfT %>%
  group_by(Year) %>%
  summarize(avgDensity = mean(groupDensity)) %>%
  ggplot(., aes(x = Year, y = as.numeric(avgDensity) * 10^10)) +
    scale_y_continuous(limits = c(0, NA)) +
    scale_x_continuous(breaks = seq(1995, 2015, 5)) +
    geom_point() +
    geom_smooth(method = lm) +
    ylab("Group Density [Tornadoes/100 x 100 sq. km]") +
    theme_minimal()
```

There is no long-term trend in annual average outbreak area. There is no long-term trend in annual average outbreak density (number of tornadoes per unit area).

Check on a map.
```{r}
tm_shape(BigDays.sfdfT) +
  tm_polygons(alpha = .1) + 
tm_shape(stateBorders, projection = "laea_NA", is.master = TRUE) + 
  tm_borders()
```

Intersect
```{r}
counties.sf <- st_transform(counties.sf, 
                            crs = st_crs(BigDays.sfdfT))
gI <- st_intersects(BigDays.sfdfT, counties.sf, sparse = FALSE)
colnames(gI) <- counties.sf$name
counties.sf$GroupDayCount <- colSums(gI)
```

Remove Alaska, Hawaii, and Puerto Rico from the `states.sf` data frame.
```{r}
states.sf <- states.sf %>% 
  filter(!stusps %in% c("AK", "PR", "HI"))
```

Create a map of the outbreak density in each county in the United States. Fill by the `GroupDayCount` column. 
```{r}
counties.sf <- st_transform(counties.sf, 
                            crs = st_crs(stateBorders))
BigDays.sfdfT <- st_transform(BigDays.sfdfT, 
                            crs = st_crs(stateBorders))

tm_shape(BigDays.sfdfT, is.master = TRUE, projection = "merc") +
  tm_polygons(alpha = 0, border.alpha = 0) +
tm_shape(counties.sf) +
   tm_fill("GroupDayCount",
            title = "Total Big Days",
            palette = "Reds", breaks = c(0, 15, 30, 45, 60)) +
  tm_borders(col = "gray", alpha = .3) +
  tm_compass(size = 5, position = c("right", "top")) + tm_scale_bar(width = 0.6, size = 1.4) +
  tm_layout(legend.position = c("right", "bottom"),
                   attr.position = c("left", "bottom"),
                   legend.frame = FALSE,
                   #title = "Tornado Group Days by County [1994-2017]",
                   #title.size = 1.3,
                   #title.position = c("left", "TOP"),
                   inner.margins = c(.15, .0, .0, 0),
            legend.width = -0.2, 
            legend.height = -0.3, 
            legend.title.size=1.5,
            legend.text.size = 1.25,
            legend.bg.color = "white",
            legend.bg.alpha =1) +
tm_shape(stateBorders, is.master = FALSE) +
  tm_borders() 
```
** Figure 4: Big day density by county **

Number of times each county was within the convex hull of a big tornado day (more than 10 tornadoes occurring in a multi-day 'outbreak' of at least 30 tornadoes, 1994-2017).

Year/date plot. Initial code from: https://buzzfeednews.github.io/2018-07-wildfire-trends/
```{r}
BigDays.sfdfT <- as.data.frame(BigDays.sfdfT) %>%
  mutate(lTED = log10(GroupDayTotalED),
         plot_date = as.Date(format(cDate, "2012-%m-%d")))
ggplot(BigDays.sfdfT, aes(y = Year)) +
  geom_hline(yintercept = seq(1994, 2017, by = 1), 
             color = "gray30", 
             size = .05) +
  scale_size(range = c(5, 9), 
             name = " ATP [GW]", 
             labels = c("10", "100", "1000", "10,000", "100,000"), 
             breaks = c(10, 11, 12, 13, 14)) +
  scale_x_date(date_breaks = "months", 
               date_labels = "%b") +
  scale_y_reverse(limits = c(2017, 1994), 
                  breaks = c(2014, 2009, 2004, 1999, 1994)) +
  xlab("Day of the Year") +  ylab("Year") +
  geom_point(aes(size = lTED, x = plot_date),  alpha = .5) +
  theme_minimal() +
  theme(text = element_text(size=30), legend.position = "bottom", legend.background = element_rect(size=0.5, linetype="solid", 
                                  colour ="gray10"))
```
**Accumulated tornado power (ATP) by day of year on days with more than 10 tornadoes occurring in a multi-day 'outbreak' of at least 30 tornadoes, 1994-2017.**

```{r, eval = FALSE}
BigDays.sfdfT %>%
  #elect(cDate, GroupDayTotalED, ATP) %>%
  top_n(n = 10) %>%
  arrange(desc(ATP))
```
Use a Spearman's correlation to quantify the relationship between ATP and the number of tornadoes.  

```{r}
cor.test(x = BigDays.sfdfT$ATP, 
         y = BigDays.sfdfT$nT, 
         method = 'spearman')
```
Spearman's rank correlation between ATP and number of tornadoes is .633

```{r}
BigDays.sfdfT %>%
  group_by(Month) %>%
  summarize(avgATP = mean(ATP),
            nT = sum(nT),
            nBD = n())

Groups.sfdfT %>%
  top_n(n = 10, wt = nT) %>%
  arrange(desc(nT))

BigDays.sfdfT %>%
  top_n(n = 10, wt = nT) %>%
  arrange(desc(nT))
```
** Table 5: Seasonal variation in ATP (TW), number of tornadoes, and the number of big days by month. The number of tornadoes and the number of big days is based on the period 1994 – 2017. **
Time series of annual number of big days in large groups and the annual average ATP across those days.
```{r}
BigDays.sfdfT %>%
  group_by(Year) %>%
  summarize(nBD = n(),
            avgATP = mean(ATP)) %>%
ggplot(., aes(x = Year, y = nBD)) +
    geom_point(aes(size = avgATP, color = avgATP), 
               alpha = .9) +
    scale_size_continuous(range = c(0, 10)) +
    scale_color_gradient(low = "yellow", high = "red", guide = "legend") + 
    scale_size(range = c(1,10)) +
    scale_fill_gradient(low="yellow", high = "red") + 
    guides(fill = guide_colourbar(reverse=TRUE) ) +
    scale_x_continuous(breaks = seq(1995, 2015, 5)) +
    scale_y_continuous(breaks = seq(5, 20, 5)) +
    labs(size = "ATP [TW]", color = "ATP [TW]") +
    xlab("Year") + ylab("Number of Big Days") +
    theme_minimal() +
  theme(text = element_text(size=20)) +
  theme(legend.position="bottom")
```
**Figure 5: Number of big days by year, 1994 – 2017. Points are sized and colored by annual average ATP.**

How many big days have an ATP > 30 TW? 
```{r}
BigDayATP <- BigDays.sfdfT %>%
  filter(ATP >= 10)

48/212 *100
```
23% of our big days have ATP greater than 10 TW. 

First calculate the mean and variance of ATP
```{r}
library(fitdistrplus)
ATP_TW <- BigDays.sfdfT$ATP

mean(ATP_TW) # 7.8
var(ATP_TW) # 309
```
Mean and varaince

First a plot visualizing the data together with some possible theoretical distributions in a skewness-kurtosis space:
``` {r}
hist(ATP_TW)
hist(log(ATP_TW)) 

descdist(ATP_TW)
```

```{r}
gammafit  <-  fitdistrplus::fitdist(ATP_TW, "gamma")
weibullfit  <-  fitdistrplus::fitdist(ATP_TW, "weibull")
lnormfit  <-  fitdistrplus::fitdist(ATP_TW, "lnorm")  # not supported?

library(flexsurv) # on CRAN

gengammafit  <-  fitdistrplus::fitdist(ATP_TW, "gengamma",
                                       start=function(d) list(mu=mean(d),
                                                              sigma=sd(d), Q = 0))

qqcomp(list(gammafit, weibullfit, lnormfit, gengammafit),
       legendtext=c("gamma", "lnorm", "weibull", "gengamma") )
```
** Lnorm and gamma fit the best ** 

Another ATP_TW
```{r}
library(car)
qqPlot(log(ATP_TW)) ## cannot assume normality because it is outside the blue line. 

qqPlot(ATP_TW, distribution = "gamma", shape = 1)
```
Because the lines do not fall inside the blue line, you cannot assume normality using the log scale. (http://www.sthda.com/english/wiki/qq-plots-quantile-quantile-plots-r-base-graphs)

Density plot of ATP.
```{r}
labels <- c("10", "100", "1000","10000", "100000")
ggplot(BigDays.sfdfT, aes(log(GroupDayTotalED))) +
  geom_histogram(binwidth = .5, color = "white", fill = "gray40") +
  scale_x_continuous(breaks = 10:14, labels= labels) +
  xlab("Accumulated Tornado Energy [TW]") +
  ylab("Frequency") +
  theme_minimal() +
  theme(text = element_text(size=20))
```
** Histogram of per big day ATP, 1994--2017. The horizontal axis is on a log scale.**

#################################
## Linear Mixed Effects Models ##
#################################

Time series of environmental factors. Mean of the maximum Bulk Shear for each big day for each month.
```{r}
BigDays.sfdfT %>%
  group_by(Year) %>%
  summarize(mEV = mean(maxBS)) %>%
ggplot(., aes(x = Year, y = mEV)) +
  geom_point() +
  scale_y_continuous(limits = c(0, NA)) +
  geom_smooth(method = lm)
```

Random effects. Summarize the average ATP and number of tornadoes by month.
```{r}
BigDays.sfdfT %>%
  group_by(Mo) %>%
  summarize(mED = mean(GroupDayTotalED)/10^12,
            nT = sum(nT))
```

Models:
```{r}
m1 <- lmer(log(GroupDayTotalED) ~ I(Year - 2004) + (1|Mo),
             weights = nT, 
             data = BigDays.sfdfT)
summary(m1) #SIG

m2 <- lmer(log(GroupDayTotalED) ~ I(Year - 2004) + (1|Mo) + maxCAPE2,
             weights = nT, 
             data = BigDays.sfdfT)
summary(m2) #SIG max...not avg

m3 <- lmer(log(GroupDayTotalED) ~ I(Year - 2004) + (1|Mo) + maxBS2,
             weights = nT, 
             data = BigDays.sfdfT)
summary(m3) #SIG max 

m4 <- lmer(log(GroupDayTotalED) ~ I(Year - 2004) + (1|Mo) + maxSM2,
             weights = nT, 
             data = BigDays.sfdfT)
summary(m4) #SIG max 

m5 <- lmer(log(GroupDayTotalED) ~ I(Year - 2004) + (1|Mo) + maxHLCY2,
             weights = nT, 
             data = BigDays.sfdfT)
summary(m5) #SIG max...not avg 

m6 <- lmer(log(GroupDayTotalED) ~ I(Year - 2004) + (1|Mo) + minCIN2,
             weights = nT, 
             data = BigDays.sfdfT)
summary(m6) #SIG max...not avg 
```

Fit the best model for log(ATP):
```{r}
model1 <- lmer(log(GroupDayTotalED) ~ I(Year - 2004) + (1|Mo) + 
                  maxCAPE2 + maxBS2 +  maxHLCY2 + minCIN2 ,
             weights = nT, 
             data = BigDays.sfdfT)

summary(model1)

model2 <- lmer(log(GroupDayTotalED) ~  I(Year - 2004) + (1|Mo) +
                 maxBS2 +  minCIN2  + maxCAPE2 * maxHLCY2,
             weights = nT, 
             data = BigDays.sfdfT)
summary(model2)

model3 <- lmer(log(GroupDayTotalED) ~ I(Year - 2004) + (1|Mo) + 
                  maxCAPE2 + maxBS2 +  maxHLCY,
             weights = nT, 
             data = BigDays.sfdfT)
summary(model3)

model4 <- lmer(log(GroupDayTotalED) ~ I(Year - 2004) + (1|Mo) + 
                  maxCAPE2 * maxBS2 +  maxHLCY2 + minCIN2 ,
             weights = nT, 
             data = BigDays.sfdfT)

summary(model4)

AIC(model1, model2, model3, model4) # model 1 is better...without the interaction
confint(model1, method = "Wald")
```

```{r, eval=FALSE}
df2 <- BigDays.sfdfT %>%
  filter(Mo > 2 & Mo < 7)

model2 <- lm(log(GroupDayTotalED) ~  I(Yr - 2004) +
                     mCAPE2 * mCIN2 + mBS2,
              weights = nT, 
              data = df2)
summary(model2)

df3 <- BigDays.sfdfT %>%
  filter(Mo <= 2 | Mo >= 7)

model3 <- lm(log(GroupDayTotalED) ~ 
                     mCAPE2 + mCIN2,
              weights = nT, 
              data = df3)
summary(model3)


AIC(model2)
confint(model2, method = "Wald")
```

Get specific values on the prediction of ATP plot. 

```{r}
#4000 CAPE and 40 BS
mpred1 <- exp(predict(model1, data.frame(maxCAPE2 = 4, maxBS2 = 4, Year = 2017, Mo = 4, minCIN2 = -2, maxHLCY2 = 4)))/10^12
#24.93 

#250 CAPE and 25 BS
mpred2 <- exp(predict(model1, data.frame(maxCAPE2 = 0.25, maxBS2 = 2.5, Year = 2017, Mo = 4, minCIN2 = -2, maxHLCY2 = 4)))/10^12
#2.82

#0 CAPE and 0 BS
exp(predict(model1, data.frame(maxCAPE2 = 0, maxBS2 = 0, Year = 2017, Mo = 4, minCIN2 = -2, maxHLCY2 = 4)))/10^12
#0.35

#3000 CAPE and 15 BS
mpred3 <- exp(predict(model1, data.frame(maxCAPE2 = 3, maxBS2 = 1.5, Year = 2017, Mo = 4, minCIN2 = -2, maxHLCY2 = 4)))/10^12
#2.56

mpred1 <- c(4000/1000, 40/10, 30.85)
mpred2 <- c(250/1000, 25/10, 28.67)
mpred3 <- c(3000/1000, 15/10, 28.57)
test <- as.data.frame(rbind(mpred1, mpred2, mpred3))
colnames(test) <- c("maxCAPE2", "maxBS2", "value")
```

Create a prediction grid. 
```{r}
library(reshape2)
pgrid <- expand.grid(maxCAPE2 = seq(.1, 5.1, length = 100),
                     maxBS2 = seq(1.2, 4.5, length = 100),
                     Year = 2017, 
                     minCIN2 = -2,
                     maxHLCY2 = 4, 
                     Mo = 4)
pgrid$pre <- predict(model1, newdata = pgrid, type = "response")

pgridL = melt(pgrid, id.vars = c("maxCAPE2", "maxBS2"), measure.vars = "pre")

#x<- matrix(pre, nrow = 5001, byrow = FALSE)
e <- c(12, 12.5, 13, 13.5)

ggplot(pgridL, aes(x = maxCAPE2 * 1000, y = maxBS2 * 10, fill = value)) +
  geom_tile( show.legend = TRUE) +
 # geom_contour(aes(z = value), color = "green") + 
  scale_fill_viridis_c(breaks = log(10^e), labels = c(1, 3.2, 10, 32)) +
  theme_bw() +
  theme(text = element_text(size=25), legend.position="bottom", legend.key.width = unit(1.75, "cm"), 
        legend.background = element_rect(size=0.5)) +
  xlab("CAPE [J/kg]") + 
  ylab("Bulk Shear [m/s]") +
  labs(fill = "ATP [TW]") + geom_point(data = test, size = 4) 
#e <- c(12,  12.5, 13, 13.5)
#ggplot(pgridL, aes(x = maxCAPE2, y = maxBS2, fill = value)) +
 # geom_raster(show.legend = TRUE) +
 # scale_fill_viridis_c(breaks = log(10^e), labels = c(1, 3.2, 10, 32))
```
**Figure 7: Predictions of ATP across a range of CAPE and bulk shear values holding CIN, helicity, year, and month as constants.  **

Table of coefficients.
```{r}
x <- summary(model1)
xtable(x$coefficients, digits = 3)
```
**Table 6: Coefficient estimates from a regression model of ATP onto year, CAPE, bulk shear, CIN, and helicity using data from n = 212 big days in large groups over the period. The standard error is on the estimate and its t value is the ratio of the estimate to the standard error. The coefficients were determined via an interactive maximum likelihood approach with the lmer function from the lme4 package for R (Bates et al. 2015)**

Observed versus predicted.
```{r}
BigDays.sfdfT$preATP <- exp(predict(model1))
cor(BigDays.sfdfT$preATP, BigDays.sfdfT$GroupDayTotalED)
```

Bulk Shear: 
min: 11
max: 45

CAPE: 
min: 60
max: 5120

preATP
min: 0.27
max: 38

ATP: 
min: 0.005
max: 220

Observed versus prediction plot for ATP.
```{r}
# .scresid : standardized conditional residuals
model1.df <- fortify(model1)
model1.df2 <- model1.df %>%
  filter(abs(.scresid) >= 1.1)

model1.df <- model1.df %>%
    mutate(density = nT/HullArea)

model1.df <- model1.df[order(model1.df$GroupDayCas),]

ggplot(model1.df, aes(x = GroupDayTotalED/10^12, y = preATP/10^12, color = log10(GroupDayCas + 1))) +
        #geom_smooth(method = lm, color = "blue", size = 1.25, se = FALSE) +
#         scale_color_viridis_c(guide = FALSE, direction = -1) +
         scale_color_continuous(guide = FALSE) +
         geom_point(size = 6) + 
         geom_abline(slope = 1, size = 1.25) +
         #geom_label_repel(aes(x = GroupDayTotalED/10^12, y = preATP/10^12, label = as.character(cDate)), color = "black", data = model1.df2, size = 6) +
         scale_x_log10(limits = c(1, 300),breaks = c(.01, .1, 1, 10, 100, 1000), labels = c(".01", ".1", "1", "10", "100", "1000")) +
         scale_y_log10(limits = c(1, 75), breaks = c(.01, .1, 1, 10, 100, 1000), labels = c(".01", ".1", "1", "10", "100", "1000")) +# breaks = c(0, 15, 30, 75, 250), labels = c(0, 5, 15, 30, 75, 250)) +
         #scale_y_log10(limits = c(1, 75), breaks = c(0,5, 15, 30, 75), labels = c(0, 5, 15, 30, 75)) +
  ylab("Predicted ATP [TW]") + xlab("ATP [TW]") +
  theme_minimal() + theme(text = element_text(size=30))
```
**Figure 8: Actual versus predicted accumulated tornado power (ATP) for the n = 212 big tornado days. The predicted are based on the regression model (Eq. 3). The color shading from dark to light indicates an increasing number of casualties. **

```{r}
p1 <- ggplot(model1.df, aes(x = .scresid)) +
  geom_histogram(binwidth = .5, color = "white", fill = "gray40") +
  xlab("Standardized Residual") + ylab("Frequency") +
  ggtitle("A") +
  theme_minimal() + theme(text = element_text(size=25))

p2 <- ggplot(model1.df, aes(x = exp(.fitted)/10^12, y = .scresid, color = factor(Mo))) +
         geom_point(size = 5) +
         scale_x_log10() +
         scale_color_discrete(name = "Month") +
  xlab("Predicted ATP [TW]") + ylab("Standardized Residual") +
  ggtitle("B") +
  theme_minimal() + theme(text = element_text(size=26))
grid.arrange(p1, p2, ncol = 1, widths = 2)

#p1 + p2 + plot_layout(ncol = 1, widths = c(2, 3))
```
**Figure 6: Conditional standardized residuals from the linear regression model. (A) Histogram and (B) Residuals as a function of predicted values of ATP. **

Outliers.
```{r}
fortify(model1) %>%
  arrange(desc(.scresid)) %>%
  dplyr::select(groupNumber, cDate, nT, GroupDayTotalED, GroupDayCas, GroupDayFat, mCAPE, mCIN, mBS, preATP, .fitted, .resid, .scresid)

model1.df <- fortify(model1)
ggplot(model1.df, aes(.scresid)) +
  geom_histogram()

plt <- sm::sm.density(model1.df$.resid, model = "normal")
plt.BigDays.sfdfT <- data.frame(x = plt$eval.points, 
                     y = plt$estimate,
                     ub = plt$upper, 
                     lb = plt$lower)

ggplot(plt.BigDays.sfdfT, aes(x = x, y = y)) +
  geom_line() +
  geom_ribbon(aes(ymin = lb, ymax = ub), fill = "gray70", alpha = .3)
```

Create a data frame of the over predicted big days. 
```{r}
dates<- c( "2011-04-19", "2014-02-20", "2017-04-03", "2003-04-24")
overpreddays <- BigDays.sfdfT %>%
  filter(as.character(cDate) %in% dates)  
```

**LOOK AT MAJOR OVER- AND UNDER- PREDICTED BIG DAYS: **
Create a data frame of the under predicted big days. 
```{r}
# underdays <- c("2003-05-04", "2008-02-05", "2011-04-27") 
# underpreddays <- BigDays.sfdfT %>%
#  filter(cDate %in% overdays)    **Returning nothing

dates <- c("1999-05-03", "2011-04-27", "2011-04-26", "2004-05-22", "2004-11-23")
underpreddays <- BigDays.sfdfT %>%
  filter(as.character(cDate) %in% dates) 
```

Create the convex hulls for the over and under predicted. 
```{r}
overpred <- st_convex_hull(overpreddays)
overpred <- st_transform(overpreddays, 
  crs = "+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")

underpred <- st_convex_hull(underpreddays)
underpred <- st_transform(underpreddays, 
  crs = "+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")
```

Map the over vs under predicted big days. Color blue and magenta. 
```{r}
stateBorders <- st_transform(stateBorders, 
                            crs = st_crs(counties.sf))
overpred <- st_transform(overpred, crs = st_crs(stateBorders))
underpred <- st_transform(underpred, crs = st_crs(stateBorders))

tm_shape(stateBorders) + 
  tm_borders(col = "black") +
  tm_compass(position = c("right", "bottom"), size = 5) + 
  tm_scale_bar(position = c("left", "bottom"), width = 0.5, size = 1.5) +
  tm_layout(inner.margins = c(.2, .05, .05, .05)) +
tm_shape(counties.sf) +
  tm_borders(col = "gray50", alpha = .3) +
tm_shape(overpred) +
  tm_polygons(col = NA, lwd = 3, alpha = 0, border.col = "blue") + 
  tm_fill(col = "blue") +
tm_shape(underpred, is.master = TRUE, projection = "merc") +
  tm_polygons(col = NA, lwd = 3, alpha = 0, border.col = "magenta") 
```
**Figure 7: Areas defininng the boundary of all tornadoes on big days. Days selected are those where the model most over predicted (blue) and most under predicted (pink) ATP. **

```{r}
underden <- underpred %>%
  mutate(density = nT/HullArea)
overden <- overpred %>%
  mutate(density = nT/HullArea)

#Convert from tornado/m2 to tornadoes/km2
u <- underden$density *10**10
mean(u)
o <- overden$density *10**10
mean(o)

t.test(as.numeric(u),as.numeric(o))
```

Get the average hull area in units of km^2
```{r}
mean(underden$HullArea /10**10) 
#52.82478 [km^2]
mean(overden$HullArea /10**10)
#37.01303 [km^2]
```

#order them by date 

The most over predicted big days.
```{r}

overdates<- c( "2011-04-19", "2014-02-20", "2017-04-03", "2003-04-24")

overpred1 <- BigDays.sfdfT %>%
  filter(cDate == "2011-04-19")
overpred2 <- BigDays.sfdfT %>%
  filter(cDate == "2014-02-20")
overpred3 <-  BigDays.sfdfT  %>%
  filter(cDate == "2017-04-03")
overpred4 <-  BigDays.sfdfT  %>%
  filter(cDate == "2003-04-24")

```

The most under predicted big days. 
```{r}
underpred1 <-  BigDays.sfdfT  %>%
  filter(cDate == "1999-05-03")
underpred2 <- BigDays.sfdfT  %>%
  filter(cDate == "2011-04-26")
underpred3 <-  BigDays.sfdfT  %>%
  filter(cDate == "2011-04-27")
underpred4 <-  BigDays.sfdfT  %>%
  filter(cDate == "2004-05-22")
underpred5 <-  BigDays.sfdfT  %>%
  filter(cDate == "2004-11-23")

dat <- rbind(underpred1,underpred2,underpred3, underpred4,underpred5,overpred1,overpred2,overpred3,overpred4)
```
** Table 7: The most over- and under-predicted big days. The actual ATP was calculated and the predicted is determined by the output of our model. **

Order by Big Days
```{r}
test <- rbind(underpred1, overpred4, underpred4, underpred5, overpred1, underpred2, underpred3, overpred2, overpred3)
```

Plot the most over and under big days. 
```{r}
work <- c("under", "over", "under", "under", "over", "under", "under", "over", "over")
test <- cbind(test, work)

tm_shape(stateBorders, projection = "merc") + 
  tm_borders(col = "grey") +
  tm_layout(legend.outside = TRUE) +
  tm_shape(dat) +
  tm_facets(by = "cDate", ncol = 3)  +
  tm_symbols(col = "mag", palette = "Reds", n = 6, alpha = .6, border.lwd = 0) +
  tm_layout(panel.labels = paste(test$cDate, test$work, test$nT), panel.label.size = 0.9, panel.label.bg.color = "grey90") 
```

It over predicts when there are less tornadoes. Under predicts when there are more. 